{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('utils')\n",
    "from split_dataset import split_dataframe_by_keys, get_fenceposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('data/features_per_tstep_first_48_hours_irregular_ts_los_prediction.csv.gz')\n",
    "outcomes_df = pd.read_csv('data/outcomes_per_seq_first_48_hours_irregular_ts_los_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stays : 52354\n",
      "Total patients : 38939\n",
      "Frac of stays resulting in death : 0.081\n",
      "Frac of patients who die : 0.109\n",
      "Frac stays > 3 days : 0.466\n",
      "Frac stays > 7 days : 0.162\n",
      "Frac stays > 11 days : 0.083\n"
     ]
    }
   ],
   "source": [
    "min_stay_hrs = 30\n",
    "keep_inds = outcomes_df['length_of_stay_in_hours']>=min_stay_hrs\n",
    "outcomes_df = outcomes_df.loc[keep_inds, :].copy().reset_index(drop=True)\n",
    "ts_df = ts_df.loc[ts_df['stay_id'].isin(outcomes_df['stay_id']), :].reset_index(drop=True)\n",
    "demographics_df = demographics_df.loc[ts_df['stay_id'].isin(outcomes_df['stay_id']), :].reset_index(drop=True)\n",
    "\n",
    "\n",
    "stay_lengths = outcomes_df['length_of_stay_in_hours'].values\n",
    "n_stays = len(outcomes_df['stay_id'].unique())\n",
    "n_patients = len(outcomes_df['subject_id'].unique())\n",
    "n_deaths = outcomes_df['in_icu_mortality'].sum()\n",
    "\n",
    "print('Total stays : %d'%n_stays)\n",
    "print('Total patients : %d'%n_patients)\n",
    "print('Frac of stays resulting in death : %.3f'%(n_deaths/n_stays))\n",
    "print('Frac of patients who die : %.3f'%(n_deaths/n_patients))\n",
    "\n",
    "for min_los in [3, 7, 11]:\n",
    "    inds = stay_lengths>=min_los*24\n",
    "    frac_above_min_los = len(stay_lengths[inds])/n_stays\n",
    "    print('Frac stays > %d days : %.3f'%(min_los, frac_above_min_los))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature_cols = ['Heart Rate', \n",
    "                    'Respiratory Rate', \n",
    "                    'O2 saturation pulseoxymetry',\n",
    "       'Non Invasive Blood Pressure systolic',\n",
    "       'Non Invasive Blood Pressure diastolic',\n",
    "        'Temperature Fahrenheit',\n",
    "        'Height (cm)',\n",
    "       'Respiratory Rate (Total)', \n",
    "       'Potassium (serum)',\n",
    "       'Sodium (serum)', \n",
    "        'Chloride (serum)', \n",
    "        'Hematocrit (serum)',\n",
    "       'Hemoglobin', \n",
    "        'Creatinine (serum)', \n",
    "        'Glucose (serum)', \n",
    "        'Magnesium', \n",
    "       'Phosphorous', \n",
    "        'Platelet Count', \n",
    "        'Glucose (whole blood)',\n",
    "        'Daily Weight', \n",
    "        'Absolute Neutrophil Count',\n",
    "        'Prothrombin time',\n",
    "        'Fibrinogen',\n",
    "        'PH (Arterial)',\n",
    "        'PH (Venous)',\n",
    "        'HCO3 (serum)',\n",
    "        'Arterial O2 pressure',\n",
    "        'Arterial CO2 Pressure',\n",
    "        'Lactic Acid',\n",
    "        'Albumin',\n",
    "        'Calcium non-ionized',\n",
    "        'C Reactive Protein (CRP)',\n",
    "        'ALT',\n",
    "        'AST',\n",
    "        'Direct Bilirubin', \n",
    "        'Total Bilirubin',\n",
    "        'Troponin-T',\n",
    "        'Venous CO2 Pressure']\n",
    "\n",
    "dem_cols = ['Age', 'is_gender_male', 'is_gender_unknown']\n",
    "id_col = ['stay_id']\n",
    "id_cols = ['subject_id', 'hadm_id', 'stay_id']\n",
    "time_col = ['minutes_from_admission']\n",
    "feature_cols = ts_feature_cols+dem_cols\n",
    "features_df = pd.merge(ts_df, demographics_df, on=id_cols, how='left')\n",
    "\n",
    "features_df['minutes_from_admission']=features_df['minutes_from_admission'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features into train valid test\n",
    "x_train_df, x_test_df = split_dataframe_by_keys(\n",
    "        features_df, cols_to_group=id_cols, size=0.2, random_state=41)\n",
    "\n",
    "x_train_df, x_valid_df = split_dataframe_by_keys(\n",
    "        x_train_df, cols_to_group=id_cols, size=0.2, random_state=41)\n",
    "\n",
    "# split outcomes into train valid test\n",
    "y_train_df, y_test_df = split_dataframe_by_keys(\n",
    "        outcomes_df, cols_to_group=id_cols, size=0.2, random_state=41)\n",
    "\n",
    "y_train_df, y_valid_df = split_dataframe_by_keys(\n",
    "        y_train_df, cols_to_group=id_cols, size=0.2, random_state=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features_df, ts_df, outcomes_df, demographics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the train/valid/test stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, y_df, x_df in [('train', y_train_df, x_train_df),\n",
    "                   ('valid', y_valid_df, x_valid_df),\n",
    "                   ('test', y_test_df, x_test_df)]:\n",
    "\n",
    "    stay_lengths = y_df['length_of_stay_in_hours'].values\n",
    "    n_stays = len(y_df['stay_id'].unique())\n",
    "    n_patients = len(y_df['subject_id'].unique())\n",
    "    n_deaths = y_df['in_icu_mortality'].sum()\n",
    "\n",
    "    print('Total stays : %d'%n_stays)\n",
    "    print('Total patients : %d'%n_patients)\n",
    "    print('Frac of stays resulting in death : %.3f'%(n_deaths/n_stays))\n",
    "    print('Frac of patients who die : %.3f'%(n_deaths/n_patients))\n",
    "    \n",
    "        \n",
    "    for min_los in [3, 7, 11]:\n",
    "        inds = stay_lengths>=min_los*24\n",
    "        frac_above_min_los = len(stay_lengths[inds])/n_stays\n",
    "        print('Frac stays > %d days in %s : %.3f'%(min_los, split, frac_above_min_los))\n",
    "        y_df['los_geq_%s_days'%min_los] = (stay_lengths>=min_los*24)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features in format for downstream models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_ts_matrix(x_df, y_df, outcome_col):\n",
    "    fp = get_fenceposts(x_df, id_cols)\n",
    "    nrows = len(fp)-1\n",
    "    T = 1440\n",
    "    D = len(feature_cols)\n",
    "\n",
    "    X_NTD = np.ones((nrows, T, D), dtype=np.float32)*np.nan\n",
    "    times_NT = np.zeros((nrows, T), dtype=np.float32)\n",
    "    y_N = np.zeros(nrows, dtype=int)\n",
    "    mask_times_NT = np.zeros((nrows, T), dtype=bool)+False\n",
    "    mask_obs_NTD = np.zeros((nrows, T, D), dtype=bool)+False\n",
    "\n",
    "#     outcome_col = 'los_geq_3_days'\n",
    "    for ii in range(nrows):\n",
    "        cur_seq_len = fp[ii+1]-fp[ii]\n",
    "        curr_vals = x_df.iloc[fp[ii]:fp[ii+1]][feature_cols].values\n",
    "        curr_ts = np.squeeze(x_df.iloc[fp[ii]:fp[ii+1]][time_col].values, axis=1)\n",
    "        curr_mask = np.logical_not(np.isnan(curr_vals))\n",
    "\n",
    "        X_NTD[ii, :cur_seq_len, :] = curr_vals\n",
    "        times_NT[ii, :cur_seq_len] = curr_ts\n",
    "        y_N[ii] = y_df.iloc[ii, :][outcome_col]\n",
    "        mask_times_NT[ii, :cur_seq_len] = True\n",
    "        mask_obs_NTD[ii, :cur_seq_len] = curr_mask\n",
    "        \n",
    "    return X_NTD, y_N, times_NT, mask_times_NT, mask_obs_NTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'data/classifier_train_test_split_dir'\n",
    "suffix = '_irregular_ts'\n",
    "for min_los in [3]:\n",
    "    outcome_col = \"los_geq_%s_days\"%min_los\n",
    "    train_X_NTD, train_y_N, train_times_NT, train_mask_times_NT, train_mask_obs_NTD = convert_csv_to_ts_matrix(x_train_df, \n",
    "                                                                                                               y_train_df,\n",
    "                                                                                                              outcome_col)\n",
    "    \n",
    "    valid_X_NTD, valid_y_N, valid_times_NT, valid_mask_times_NT, valid_mask_obs_NTD = convert_csv_to_ts_matrix(x_valid_df, \n",
    "                                                                                                               y_valid_df,\n",
    "                                                                                                              outcome_col)\n",
    "    test_X_NTD, test_y_N, test_times_NT, test_mask_times_NT, test_mask_obs_NTD = convert_csv_to_ts_matrix(x_test_df, \n",
    "                                                                                                          y_test_df,\n",
    "                                                                                                         outcome_col)\n",
    "    \n",
    "    \n",
    "    \n",
    "    D = train_X_NTD.shape[-1]\n",
    "    \n",
    "    \n",
    "    norm_dict_list = []\n",
    "    # normalize the data exactly as per mtan\n",
    "    for d in range(D):\n",
    "        mins = np.nanpercentile(train_X_NTD[:, :, d], 1)\n",
    "        maxs = np.nanpercentile(train_X_NTD[:, :, d], 99)\n",
    "        \n",
    "        norm_dict = {'feature' : ts_feature_cols[d],\n",
    "                     'min' : mins,\n",
    "                     'max' : maxs}\n",
    "        \n",
    "        if maxs==0:\n",
    "            maxs=1\n",
    "        train_X_NTD[:, :, d] = (train_X_NTD[:, :, d]-mins)/maxs\n",
    "        valid_X_NTD[:, :, d] = (valid_X_NTD[:, :, d]-mins)/maxs\n",
    "        test_X_NTD[:, :, d] = (test_X_NTD[:, :, d]-mins)/maxs\n",
    "        \n",
    "        norm_dict_list.append(norm_dict)\n",
    "    norm_df = pd.DataFrame(norm_dict_list)\n",
    "    norm_df.to_csv(os.path.join(curr_save_dir, 'normalization_estimates.csv'), index=False)\n",
    "        \n",
    "    curr_save_dir = save_dir\n",
    "    \n",
    "    \n",
    "    # replace the nan values with 0s\n",
    "    train_X_NTD[np.isnan(train_X_NTD)]=0\n",
    "    valid_X_NTD[np.isnan(valid_X_NTD)]=0\n",
    "    test_X_NTD[np.isnan(test_X_NTD)]=0\n",
    "    \n",
    "    # normalize the observed timepoints between 0 and 1\n",
    "    max_t = np.max(train_times_NT)\n",
    "    train_times_NT = train_times_NT/max_t\n",
    "    valid_times_NT = valid_times_NT/max_t\n",
    "    test_times_NT = test_times_NT/max_t\n",
    "    \n",
    "    print('Saving data to %s'%curr_save_dir)\n",
    "    np.save(os.path.join(curr_save_dir, 'X_train%s.npy'%suffix), \n",
    "            train_X_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_train%s.npy'%suffix), \n",
    "            train_y_N)\n",
    "    np.save(os.path.join(curr_save_dir, 'train_times_NT%s.npy'%suffix), \n",
    "            train_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'train_mask_times_NT%s.npy'%suffix), \n",
    "            train_mask_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'train_mask_obs_NTD%s.npy'%suffix), \n",
    "            train_mask_obs_NTD)\n",
    "\n",
    "    print('Done saving train..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_valid%s.npy'%suffix), \n",
    "            valid_X_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_valid%s.npy'%suffix), \n",
    "            valid_y_N)\n",
    "    np.save(os.path.join(curr_save_dir, 'valid_times_NT%s.npy'%suffix), \n",
    "            valid_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'valid_mask_times_NT%s.npy'%suffix), \n",
    "            valid_mask_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'valid_mask_obs_NTD%s.npy'%suffix), \n",
    "            valid_mask_obs_NTD)\n",
    "\n",
    "    print('Done saving valid..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_test%s.npy'%suffix), \n",
    "            test_X_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_test%s.npy'%suffix), \n",
    "            test_y_N)\n",
    "    np.save(os.path.join(curr_save_dir, 'test_times_NT%s.npy'%suffix), \n",
    "            test_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'test_mask_times_NT%s.npy'%suffix), \n",
    "            test_mask_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'test_mask_obs_NTD%s.npy'%suffix), \n",
    "            test_mask_obs_NTD)\n",
    "\n",
    "    print('Done saving test..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
